{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfafaa7-63f0-4e1e-93cb-763f2fde70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad343729-b74a-47b9-957b-b699a0833f38",
   "metadata": {},
   "source": [
    "# First with pytorch library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebd42a8-ef2e-49a0-86ed-6676b5628c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIFAR10',\n",
       " 'CIFAR100',\n",
       " 'CLEVRClassification',\n",
       " 'CREStereo',\n",
       " 'Caltech101',\n",
       " 'Caltech256',\n",
       " 'CarlaStereo',\n",
       " 'CelebA',\n",
       " 'Cityscapes',\n",
       " 'CocoCaptions',\n",
       " 'CocoDetection',\n",
       " 'Country211',\n",
       " 'DTD',\n",
       " 'DatasetFolder',\n",
       " 'EMNIST',\n",
       " 'ETH3DStereo',\n",
       " 'EuroSAT',\n",
       " 'FER2013',\n",
       " 'FGVCAircraft',\n",
       " 'FakeData',\n",
       " 'FallingThingsStereo',\n",
       " 'FashionMNIST',\n",
       " 'Flickr30k',\n",
       " 'Flickr8k',\n",
       " 'Flowers102',\n",
       " 'FlyingChairs',\n",
       " 'FlyingThings3D',\n",
       " 'Food101',\n",
       " 'GTSRB',\n",
       " 'HD1K',\n",
       " 'HMDB51',\n",
       " 'INaturalist',\n",
       " 'ImageFolder',\n",
       " 'ImageNet',\n",
       " 'Imagenette',\n",
       " 'InStereo2k',\n",
       " 'KMNIST',\n",
       " 'Kinetics',\n",
       " 'Kitti',\n",
       " 'Kitti2012Stereo',\n",
       " 'Kitti2015Stereo',\n",
       " 'KittiFlow',\n",
       " 'LFWPairs',\n",
       " 'LFWPeople',\n",
       " 'LSUN',\n",
       " 'LSUNClass',\n",
       " 'MNIST',\n",
       " 'Middlebury2014Stereo',\n",
       " 'MovingMNIST',\n",
       " 'Omniglot',\n",
       " 'OxfordIIITPet',\n",
       " 'PCAM',\n",
       " 'PhotoTour',\n",
       " 'Places365',\n",
       " 'QMNIST',\n",
       " 'RenderedSST2',\n",
       " 'SBDataset',\n",
       " 'SBU',\n",
       " 'SEMEION',\n",
       " 'STL10',\n",
       " 'SUN397',\n",
       " 'SVHN',\n",
       " 'SceneFlowStereo',\n",
       " 'Sintel',\n",
       " 'SintelStereo',\n",
       " 'StanfordCars',\n",
       " 'UCF101',\n",
       " 'USPS',\n",
       " 'VOCDetection',\n",
       " 'VOCSegmentation',\n",
       " 'VisionDataset',\n",
       " 'WIDERFace',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_optical_flow',\n",
       " '_stereo_matching',\n",
       " 'caltech',\n",
       " 'celeba',\n",
       " 'cifar',\n",
       " 'cityscapes',\n",
       " 'clevr',\n",
       " 'coco',\n",
       " 'country211',\n",
       " 'dtd',\n",
       " 'eurosat',\n",
       " 'fakedata',\n",
       " 'fer2013',\n",
       " 'fgvc_aircraft',\n",
       " 'flickr',\n",
       " 'flowers102',\n",
       " 'folder',\n",
       " 'food101',\n",
       " 'gtsrb',\n",
       " 'hmdb51',\n",
       " 'imagenet',\n",
       " 'imagenette',\n",
       " 'inaturalist',\n",
       " 'kinetics',\n",
       " 'kitti',\n",
       " 'lfw',\n",
       " 'lsun',\n",
       " 'mnist',\n",
       " 'moving_mnist',\n",
       " 'omniglot',\n",
       " 'oxford_iiit_pet',\n",
       " 'pcam',\n",
       " 'phototour',\n",
       " 'places365',\n",
       " 'rendered_sst2',\n",
       " 'sbd',\n",
       " 'sbu',\n",
       " 'semeion',\n",
       " 'stanford_cars',\n",
       " 'stl10',\n",
       " 'sun397',\n",
       " 'svhn',\n",
       " 'ucf101',\n",
       " 'usps',\n",
       " 'utils',\n",
       " 'video_utils',\n",
       " 'vision',\n",
       " 'voc',\n",
       " 'widerface']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdd4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just some preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor() , transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b609290a-e5f7-44e3-a611-e175819ab503",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(root = \"data\" , train=True , download= True , transform= transform)\n",
    "testing_data = datasets.MNIST(root = \"data\" , download=True , train= False , transform= transform)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf2a821-7a8f-4768-a430-40e9dfb9d290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testing_data[0][0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54459f7-3e8f-4d62-951a-e6f6ba7c32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data , shuffle=True , batch_size=64)\n",
    "test_dataloader = DataLoader(testing_data , shuffle=True, batch_size=64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f3a03c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the dataloader \n",
    "img , label = next(iter(test_dataloader))\n",
    "plt.imshow(img[0].squeeze()) \n",
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24c6a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1 , 128 , 5)\n",
    "        self.conv2 = nn.Conv2d(128 , 256 , 5)\n",
    "        self.fc1 = nn.Linear(256 * 10 * 10 , 512, bias=True)\n",
    "        self.fc2 = nn.Linear(512 , 128)\n",
    "        self.fc3 = nn.Linear(128 , 10)\n",
    "    \n",
    "    def forward(self , x ):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x , 2)\n",
    "        x = torch.flatten(x , 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        op = F.log_softmax(x , dim = 1)\n",
    "        return op \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0724db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet().to(device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a514826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=25600, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0ec8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters() , lr=0.01 , momentum=0.8)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9162dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f091466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model , train_data , device , optimizer , epoch  ): \n",
    "    '''model.train() tells your model that you are training the model. This helps inform layers such as Dropout and BatchNorm, which are designed to behave differently during training and evaluation.\n",
    "      For instance, in training mode, BatchNorm updates a moving average on each new batch; whereas, for evaluation mode, these updates are frozen.\n",
    "    More details: model.train() sets the mode to train (see source code). You can call either model.eval() or model.train(mode=False) to tell that you are testing. \n",
    "    It is somewhat intuitive to expect train function to train model but it does not do that. It just sets the mode.'''\n",
    "    model.train()\n",
    "    for batch , (data , label) in enumerate(train_data):\n",
    "        data , label = data.to(device) , label.to(device)\n",
    "        optimizer.zero_grad() # zeros out the weights \n",
    "        output = model(data)\n",
    "        loss = loss_fn(output , label)\n",
    "        loss.backward()\n",
    "        optimizer.step()# performs weight update \n",
    "        print(f\"Epoch{epoch}| Training Loss :{loss}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "846ed09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model , test_data , device):\n",
    "    model.eval()\n",
    "    for data , label in test_data:\n",
    "        data , label = data.to(device) , label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_fn(pred ,label)\n",
    "        print(f\"Test loss : {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6180ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1| Training Loss :0.001705596107058227\n",
      "Epoch1| Training Loss :0.004793809726834297\n",
      "Epoch1| Training Loss :0.003847738727927208\n",
      "Epoch1| Training Loss :0.004473344422876835\n",
      "Epoch1| Training Loss :0.01559675857424736\n",
      "Epoch1| Training Loss :0.08140085637569427\n",
      "Epoch1| Training Loss :0.02008131518959999\n",
      "Epoch1| Training Loss :0.009924937970936298\n",
      "Epoch1| Training Loss :0.004557115491479635\n",
      "Epoch1| Training Loss :0.02444801665842533\n",
      "Epoch1| Training Loss :0.0049202656373381615\n",
      "Epoch1| Training Loss :0.01021316647529602\n",
      "Epoch1| Training Loss :0.007715798914432526\n",
      "Epoch1| Training Loss :0.014616915956139565\n",
      "Epoch1| Training Loss :0.012217029929161072\n",
      "Epoch1| Training Loss :0.01129236351698637\n",
      "Epoch1| Training Loss :0.002604045905172825\n",
      "Epoch1| Training Loss :0.0009863566374406219\n",
      "Epoch1| Training Loss :0.0023041139356791973\n",
      "Epoch1| Training Loss :0.07776045054197311\n",
      "Epoch1| Training Loss :0.00330218393355608\n",
      "Epoch1| Training Loss :0.03545919805765152\n",
      "Epoch1| Training Loss :0.008809550665318966\n",
      "Epoch1| Training Loss :0.015583956614136696\n",
      "Epoch1| Training Loss :0.004067050293087959\n",
      "Epoch1| Training Loss :0.028046267107129097\n",
      "Epoch1| Training Loss :0.05519629269838333\n",
      "Epoch1| Training Loss :0.004930042661726475\n",
      "Epoch1| Training Loss :0.043479010462760925\n",
      "Epoch1| Training Loss :0.12349683791399002\n",
      "Epoch1| Training Loss :0.041341859847307205\n",
      "Epoch1| Training Loss :0.00997075717896223\n",
      "Epoch1| Training Loss :0.007178715895861387\n",
      "Epoch1| Training Loss :0.03356995806097984\n",
      "Epoch1| Training Loss :0.03338631987571716\n",
      "Epoch1| Training Loss :0.005138332024216652\n",
      "Epoch1| Training Loss :0.0072099813260138035\n",
      "Epoch1| Training Loss :0.0009378429967910051\n",
      "Epoch1| Training Loss :0.03732623532414436\n",
      "Epoch1| Training Loss :0.015047558583319187\n",
      "Epoch1| Training Loss :0.013212071731686592\n",
      "Epoch1| Training Loss :0.03218919038772583\n",
      "Epoch1| Training Loss :0.002885513473302126\n",
      "Epoch1| Training Loss :0.013090211898088455\n",
      "Epoch1| Training Loss :0.14073039591312408\n",
      "Epoch1| Training Loss :0.015103820711374283\n",
      "Epoch1| Training Loss :0.01007329672574997\n",
      "Epoch1| Training Loss :0.0022461675107479095\n",
      "Epoch1| Training Loss :0.03428129106760025\n",
      "Epoch1| Training Loss :0.0010729843052104115\n",
      "Epoch1| Training Loss :0.036449532955884933\n",
      "Epoch1| Training Loss :0.027442235499620438\n",
      "Epoch1| Training Loss :0.03877297043800354\n",
      "Epoch1| Training Loss :0.015934748575091362\n",
      "Epoch1| Training Loss :0.0027031777426600456\n",
      "Epoch1| Training Loss :0.08274416625499725\n",
      "Epoch1| Training Loss :0.001893659820780158\n",
      "Epoch1| Training Loss :0.011504110880196095\n",
      "Epoch1| Training Loss :0.007463047280907631\n",
      "Epoch1| Training Loss :0.024775918573141098\n",
      "Epoch1| Training Loss :0.00678891921415925\n",
      "Epoch1| Training Loss :0.04541819170117378\n",
      "Epoch1| Training Loss :0.023891126736998558\n",
      "Epoch1| Training Loss :0.01471521332859993\n",
      "Epoch1| Training Loss :0.0014432427706196904\n",
      "Epoch1| Training Loss :0.0015142324846237898\n",
      "Epoch1| Training Loss :0.018795153126120567\n",
      "Epoch1| Training Loss :0.01194586232304573\n",
      "Epoch1| Training Loss :0.0028789318166673183\n",
      "Epoch1| Training Loss :0.05780283361673355\n",
      "Epoch1| Training Loss :0.024938756600022316\n",
      "Epoch1| Training Loss :0.006152948830276728\n",
      "Epoch1| Training Loss :0.002202909206971526\n",
      "Epoch1| Training Loss :0.07863649725914001\n",
      "Epoch1| Training Loss :0.005084063392132521\n",
      "Epoch1| Training Loss :0.0944647490978241\n",
      "Epoch1| Training Loss :0.0022696428932249546\n",
      "Epoch1| Training Loss :0.031423673033714294\n",
      "Epoch1| Training Loss :0.04827983304858208\n",
      "Epoch1| Training Loss :0.005191219039261341\n",
      "Epoch1| Training Loss :0.014195049181580544\n",
      "Epoch1| Training Loss :0.014564174227416515\n",
      "Epoch1| Training Loss :0.0728551521897316\n",
      "Epoch1| Training Loss :0.0038779452443122864\n",
      "Epoch1| Training Loss :0.01647605560719967\n",
      "Epoch1| Training Loss :0.09543333947658539\n",
      "Epoch1| Training Loss :0.044738441705703735\n",
      "Epoch1| Training Loss :0.064324289560318\n",
      "Epoch1| Training Loss :0.006725604180246592\n",
      "Epoch1| Training Loss :0.001527541782706976\n",
      "Epoch1| Training Loss :0.002578397747129202\n",
      "Epoch1| Training Loss :0.060891468077898026\n",
      "Epoch1| Training Loss :0.04316151887178421\n",
      "Epoch1| Training Loss :0.0038559073582291603\n",
      "Epoch1| Training Loss :0.07263720035552979\n",
      "Epoch1| Training Loss :0.011359757743775845\n",
      "Epoch1| Training Loss :0.02163904532790184\n",
      "Epoch1| Training Loss :0.010264174081385136\n",
      "Epoch1| Training Loss :0.011480888351798058\n",
      "Epoch1| Training Loss :0.012934180907905102\n",
      "Epoch1| Training Loss :0.011479287408292294\n",
      "Epoch1| Training Loss :0.037487149238586426\n",
      "Epoch1| Training Loss :0.07301191985607147\n",
      "Epoch1| Training Loss :0.012953083030879498\n",
      "Epoch1| Training Loss :0.021899543702602386\n",
      "Epoch1| Training Loss :0.0030265487730503082\n",
      "Epoch1| Training Loss :0.06812399625778198\n",
      "Epoch1| Training Loss :0.06737260520458221\n",
      "Epoch1| Training Loss :0.06673788279294968\n",
      "Epoch1| Training Loss :0.0029001845978200436\n",
      "Epoch1| Training Loss :0.0404614694416523\n",
      "Epoch1| Training Loss :0.007287889253348112\n",
      "Epoch1| Training Loss :0.018371662124991417\n",
      "Epoch1| Training Loss :0.06823936104774475\n",
      "Epoch1| Training Loss :0.005688292905688286\n",
      "Epoch1| Training Loss :0.01767515391111374\n",
      "Epoch1| Training Loss :0.014255360700190067\n",
      "Epoch1| Training Loss :0.011281922459602356\n",
      "Epoch1| Training Loss :0.035998567938804626\n",
      "Epoch1| Training Loss :0.011684892699122429\n",
      "Epoch1| Training Loss :0.0027121356688439846\n",
      "Epoch1| Training Loss :0.006551994476467371\n",
      "Epoch1| Training Loss :0.008092530071735382\n",
      "Epoch1| Training Loss :0.0032772812992334366\n",
      "Epoch1| Training Loss :0.013715374283492565\n",
      "Epoch1| Training Loss :0.042877744883298874\n",
      "Epoch1| Training Loss :0.005061788950115442\n",
      "Epoch1| Training Loss :0.06927512586116791\n",
      "Epoch1| Training Loss :0.007855464704334736\n",
      "Epoch1| Training Loss :0.003123457543551922\n",
      "Epoch1| Training Loss :0.0035660876892507076\n",
      "Epoch1| Training Loss :0.036140356212854385\n",
      "Epoch1| Training Loss :0.008405769243836403\n",
      "Epoch1| Training Loss :0.005836028605699539\n",
      "Epoch1| Training Loss :0.001992332749068737\n",
      "Epoch1| Training Loss :0.054427970200777054\n",
      "Epoch1| Training Loss :0.0663139671087265\n",
      "Epoch1| Training Loss :0.013944990001618862\n",
      "Epoch1| Training Loss :0.059021588414907455\n",
      "Epoch1| Training Loss :0.018548108637332916\n",
      "Epoch1| Training Loss :0.05991499871015549\n",
      "Epoch1| Training Loss :0.02810121700167656\n",
      "Epoch1| Training Loss :0.016670633107423782\n",
      "Epoch1| Training Loss :0.0027890834026038647\n",
      "Epoch1| Training Loss :0.0866066962480545\n",
      "Epoch1| Training Loss :0.007462105248123407\n",
      "Epoch1| Training Loss :0.007223497144877911\n",
      "Epoch1| Training Loss :0.01049074437469244\n",
      "Epoch1| Training Loss :0.021923936903476715\n",
      "Epoch1| Training Loss :0.0459849089384079\n",
      "Epoch1| Training Loss :0.003079033922404051\n",
      "Epoch1| Training Loss :0.055291056632995605\n",
      "Epoch1| Training Loss :0.005895883776247501\n",
      "Epoch1| Training Loss :0.0192098505795002\n",
      "Epoch1| Training Loss :0.0492577999830246\n",
      "Epoch1| Training Loss :0.0051895189099013805\n",
      "Epoch1| Training Loss :0.003301175544038415\n",
      "Epoch1| Training Loss :0.025857295840978622\n",
      "Epoch1| Training Loss :0.009462269954383373\n",
      "Epoch1| Training Loss :0.03562965244054794\n",
      "Epoch1| Training Loss :0.03524212911725044\n",
      "Epoch1| Training Loss :0.0007925553945824504\n",
      "Epoch1| Training Loss :0.03273444250226021\n",
      "Epoch1| Training Loss :0.009538058191537857\n",
      "Epoch1| Training Loss :0.009775345213711262\n",
      "Epoch1| Training Loss :0.10227984189987183\n",
      "Epoch1| Training Loss :0.0543944276869297\n",
      "Epoch1| Training Loss :0.011706538498401642\n",
      "Epoch1| Training Loss :0.005701864138245583\n",
      "Epoch1| Training Loss :0.01970977894961834\n",
      "Epoch1| Training Loss :0.014551106840372086\n",
      "Epoch1| Training Loss :0.0019904617220163345\n",
      "Epoch1| Training Loss :0.007254134863615036\n",
      "Epoch1| Training Loss :0.007482171058654785\n",
      "Epoch1| Training Loss :0.052312061190605164\n",
      "Epoch1| Training Loss :0.03402101993560791\n",
      "Epoch1| Training Loss :0.027791351079940796\n",
      "Epoch1| Training Loss :0.045914825052022934\n",
      "Epoch1| Training Loss :0.013469487428665161\n",
      "Epoch1| Training Loss :0.0083148293197155\n",
      "Epoch1| Training Loss :0.004234408959746361\n",
      "Epoch1| Training Loss :0.00943058542907238\n",
      "Epoch1| Training Loss :0.025170810520648956\n",
      "Epoch1| Training Loss :0.0023484141565859318\n",
      "Epoch1| Training Loss :0.08538311719894409\n",
      "Epoch1| Training Loss :0.027485975995659828\n",
      "Epoch1| Training Loss :0.02459481917321682\n",
      "Epoch1| Training Loss :0.016710644587874413\n",
      "Epoch1| Training Loss :0.02113211899995804\n",
      "Epoch1| Training Loss :0.02536052092909813\n",
      "Epoch1| Training Loss :0.03499959409236908\n",
      "Epoch1| Training Loss :0.022853532806038857\n",
      "Epoch1| Training Loss :0.0006025154725648463\n",
      "Epoch1| Training Loss :0.001049321610480547\n",
      "Epoch1| Training Loss :0.0029147835448384285\n",
      "Epoch1| Training Loss :0.036508020013570786\n",
      "Epoch1| Training Loss :0.09567588567733765\n",
      "Epoch1| Training Loss :0.022882573306560516\n",
      "Epoch1| Training Loss :0.10243912041187286\n",
      "Epoch1| Training Loss :0.0019153975881636143\n",
      "Epoch1| Training Loss :0.15257784724235535\n",
      "Epoch1| Training Loss :0.005165833048522472\n",
      "Epoch1| Training Loss :0.006568363402038813\n",
      "Epoch1| Training Loss :0.0036698956973850727\n",
      "Epoch1| Training Loss :0.08008334785699844\n",
      "Epoch1| Training Loss :0.13705851137638092\n",
      "Epoch1| Training Loss :0.16336414217948914\n",
      "Epoch1| Training Loss :0.017242323607206345\n",
      "Epoch1| Training Loss :0.052350353449583054\n",
      "Epoch1| Training Loss :0.01055174134671688\n",
      "Epoch1| Training Loss :0.01004131231456995\n",
      "Epoch1| Training Loss :0.0186225064098835\n",
      "Epoch1| Training Loss :0.013666592538356781\n",
      "Epoch1| Training Loss :0.08456268906593323\n",
      "Epoch1| Training Loss :0.011369872838258743\n",
      "Epoch1| Training Loss :0.04926728829741478\n",
      "Epoch1| Training Loss :0.036340948194265366\n",
      "Epoch1| Training Loss :0.0011629140935838223\n",
      "Epoch1| Training Loss :0.006976686418056488\n",
      "Epoch1| Training Loss :0.01736484467983246\n",
      "Epoch1| Training Loss :0.0928829088807106\n",
      "Epoch1| Training Loss :0.018704663962125778\n",
      "Epoch1| Training Loss :0.005732919555157423\n",
      "Epoch1| Training Loss :0.023996444419026375\n",
      "Epoch1| Training Loss :0.08995431661605835\n",
      "Epoch1| Training Loss :0.005738027393817902\n",
      "Epoch1| Training Loss :0.01851186715066433\n",
      "Epoch1| Training Loss :0.0031140665523707867\n",
      "Epoch1| Training Loss :0.044044218957424164\n",
      "Epoch1| Training Loss :0.007926286198198795\n",
      "Epoch1| Training Loss :0.020077887922525406\n",
      "Epoch1| Training Loss :0.007370888255536556\n",
      "Epoch1| Training Loss :0.038045912981033325\n",
      "Epoch1| Training Loss :0.05014423653483391\n",
      "Epoch1| Training Loss :0.016831830143928528\n",
      "Epoch1| Training Loss :0.006540382280945778\n",
      "Epoch1| Training Loss :0.0035537169314920902\n",
      "Epoch1| Training Loss :0.01321533601731062\n",
      "Epoch1| Training Loss :0.0029095634818077087\n",
      "Epoch1| Training Loss :0.001656136242672801\n",
      "Epoch1| Training Loss :0.06024521216750145\n",
      "Epoch1| Training Loss :0.09018249064683914\n",
      "Epoch1| Training Loss :0.019704697653651237\n",
      "Epoch1| Training Loss :0.13059745728969574\n",
      "Epoch1| Training Loss :0.02359042875468731\n",
      "Epoch1| Training Loss :0.011021186597645283\n",
      "Epoch1| Training Loss :0.01847723312675953\n",
      "Epoch1| Training Loss :0.010408388450741768\n",
      "Epoch1| Training Loss :0.015196351334452629\n",
      "Epoch1| Training Loss :0.054981108754873276\n",
      "Epoch1| Training Loss :0.008283010683953762\n",
      "Epoch1| Training Loss :0.005243199877440929\n",
      "Epoch1| Training Loss :0.02191455103456974\n",
      "Epoch1| Training Loss :0.030160963535308838\n",
      "Epoch1| Training Loss :0.004179786890745163\n",
      "Epoch1| Training Loss :0.04551815614104271\n",
      "Epoch1| Training Loss :0.0037284004501998425\n",
      "Epoch1| Training Loss :0.002676069736480713\n",
      "Epoch1| Training Loss :0.009389874525368214\n",
      "Epoch1| Training Loss :0.01792132295668125\n",
      "Epoch1| Training Loss :0.02243652753531933\n",
      "Epoch1| Training Loss :0.008141612634062767\n",
      "Epoch1| Training Loss :0.0031111882999539375\n",
      "Epoch1| Training Loss :0.004886919632554054\n",
      "Epoch1| Training Loss :0.0037192092277109623\n",
      "Epoch1| Training Loss :0.003942376468330622\n",
      "Epoch1| Training Loss :0.18520325422286987\n",
      "Epoch1| Training Loss :0.0640869140625\n",
      "Epoch1| Training Loss :0.04216515272855759\n",
      "Epoch1| Training Loss :0.045375317335128784\n",
      "Epoch1| Training Loss :0.004672964569181204\n",
      "Epoch1| Training Loss :0.007090777158737183\n",
      "Epoch1| Training Loss :0.014015641994774342\n",
      "Epoch1| Training Loss :0.006315447390079498\n",
      "Epoch1| Training Loss :0.012838901951909065\n",
      "Epoch1| Training Loss :0.03589731827378273\n",
      "Epoch1| Training Loss :0.0335540696978569\n",
      "Epoch1| Training Loss :0.005734264850616455\n",
      "Epoch1| Training Loss :0.02763526327908039\n",
      "Epoch1| Training Loss :0.002153591252863407\n",
      "Epoch1| Training Loss :0.028444955125451088\n",
      "Epoch1| Training Loss :0.03327895700931549\n",
      "Epoch1| Training Loss :0.052239418029785156\n",
      "Epoch1| Training Loss :0.0065099322237074375\n",
      "Epoch1| Training Loss :0.003905437421053648\n",
      "Epoch1| Training Loss :0.00977962464094162\n",
      "Epoch1| Training Loss :0.03421670198440552\n",
      "Epoch1| Training Loss :0.02318214438855648\n",
      "Epoch1| Training Loss :0.05085337907075882\n",
      "Epoch1| Training Loss :0.0010195844806730747\n",
      "Epoch1| Training Loss :0.014925184659659863\n",
      "Epoch1| Training Loss :0.11064887046813965\n",
      "Epoch1| Training Loss :0.007114572916179895\n",
      "Epoch1| Training Loss :0.01403565052896738\n",
      "Epoch1| Training Loss :0.011110903695225716\n",
      "Epoch1| Training Loss :0.002657793927937746\n",
      "Epoch1| Training Loss :0.01921389438211918\n",
      "Epoch1| Training Loss :0.0694863349199295\n",
      "Epoch1| Training Loss :0.05090467631816864\n",
      "Epoch1| Training Loss :0.053541310131549835\n",
      "Epoch1| Training Loss :0.00416884059086442\n",
      "Epoch1| Training Loss :0.009872677735984325\n",
      "Epoch1| Training Loss :0.03368546441197395\n",
      "Epoch1| Training Loss :0.04429084435105324\n",
      "Epoch1| Training Loss :0.007318826392292976\n",
      "Epoch1| Training Loss :0.05601084232330322\n",
      "Epoch1| Training Loss :0.031619563698768616\n",
      "Epoch1| Training Loss :0.05156897380948067\n",
      "Epoch1| Training Loss :0.04208768904209137\n",
      "Epoch1| Training Loss :0.007924981415271759\n",
      "Epoch1| Training Loss :0.06152980774641037\n",
      "Epoch1| Training Loss :0.004449411761015654\n",
      "Epoch1| Training Loss :0.023216504603624344\n",
      "Epoch1| Training Loss :0.004832668229937553\n",
      "Epoch1| Training Loss :0.022818367928266525\n",
      "Epoch1| Training Loss :0.04044955223798752\n",
      "Epoch1| Training Loss :0.013488844968378544\n",
      "Epoch1| Training Loss :0.056336916983127594\n",
      "Epoch1| Training Loss :0.132916659116745\n",
      "Epoch1| Training Loss :0.010755196213722229\n",
      "Epoch1| Training Loss :0.10324645787477493\n",
      "Epoch1| Training Loss :0.05987785756587982\n",
      "Epoch1| Training Loss :0.09883645921945572\n",
      "Epoch1| Training Loss :0.03309274837374687\n",
      "Epoch1| Training Loss :0.09839985519647598\n",
      "Epoch1| Training Loss :0.058397747576236725\n",
      "Epoch1| Training Loss :0.010135388933122158\n",
      "Epoch1| Training Loss :0.0022768964990973473\n",
      "Epoch1| Training Loss :0.01212031114846468\n",
      "Epoch1| Training Loss :0.028484420850872993\n",
      "Epoch1| Training Loss :0.0787758082151413\n",
      "Epoch1| Training Loss :0.03731703758239746\n",
      "Epoch1| Training Loss :0.007833135314285755\n",
      "Epoch1| Training Loss :0.009803427383303642\n",
      "Epoch1| Training Loss :0.025685252621769905\n",
      "Epoch1| Training Loss :0.016242103651165962\n",
      "Epoch1| Training Loss :0.026788683608174324\n",
      "Epoch1| Training Loss :0.009296063333749771\n",
      "Epoch1| Training Loss :0.002780077513307333\n",
      "Epoch1| Training Loss :0.051592759788036346\n",
      "Epoch1| Training Loss :0.029336582869291306\n",
      "Epoch1| Training Loss :0.046019721776247025\n",
      "Epoch1| Training Loss :0.005515180993825197\n",
      "Epoch1| Training Loss :0.04159417748451233\n",
      "Epoch1| Training Loss :0.13731469213962555\n",
      "Epoch1| Training Loss :0.034800682216882706\n",
      "Epoch1| Training Loss :0.09231036901473999\n",
      "Epoch1| Training Loss :0.0025404952466487885\n",
      "Epoch1| Training Loss :0.03704250976443291\n",
      "Epoch1| Training Loss :0.005597369745373726\n",
      "Epoch1| Training Loss :0.025571798905730247\n",
      "Epoch1| Training Loss :0.02028605155646801\n",
      "Epoch1| Training Loss :0.029455916956067085\n",
      "Epoch1| Training Loss :0.0116469357162714\n",
      "Epoch1| Training Loss :0.007787227164953947\n",
      "Epoch1| Training Loss :0.0018490009242668748\n",
      "Epoch1| Training Loss :0.06628948450088501\n",
      "Epoch1| Training Loss :0.05812922865152359\n",
      "Epoch1| Training Loss :0.0265192948281765\n",
      "Epoch1| Training Loss :0.03673454746603966\n",
      "Epoch1| Training Loss :0.10418008267879486\n",
      "Epoch1| Training Loss :0.07205585390329361\n",
      "Epoch1| Training Loss :0.04548313096165657\n",
      "Epoch1| Training Loss :0.006435081362724304\n",
      "Epoch1| Training Loss :0.002163401572033763\n",
      "Epoch1| Training Loss :0.08300486952066422\n",
      "Epoch1| Training Loss :0.03134750574827194\n",
      "Epoch1| Training Loss :0.25490885972976685\n",
      "Epoch1| Training Loss :0.03441557288169861\n",
      "Epoch1| Training Loss :0.05384138971567154\n",
      "Epoch1| Training Loss :0.01949901506304741\n",
      "Epoch1| Training Loss :0.01951117068529129\n",
      "Epoch1| Training Loss :0.05337033048272133\n",
      "Epoch1| Training Loss :0.010018553584814072\n",
      "Epoch1| Training Loss :0.15365329384803772\n",
      "Epoch1| Training Loss :0.02964269369840622\n",
      "Epoch1| Training Loss :0.057520490139722824\n",
      "Epoch1| Training Loss :0.06902457773685455\n",
      "Epoch1| Training Loss :0.008045254275202751\n",
      "Epoch1| Training Loss :0.0038771575782448053\n",
      "Epoch1| Training Loss :0.01183447614312172\n",
      "Epoch1| Training Loss :0.03265628218650818\n",
      "Epoch1| Training Loss :0.005420038942247629\n",
      "Epoch1| Training Loss :0.006303302478045225\n",
      "Epoch1| Training Loss :0.00945607665926218\n",
      "Epoch1| Training Loss :0.007707339711487293\n",
      "Epoch1| Training Loss :0.009668208658695221\n",
      "Epoch1| Training Loss :0.06479227542877197\n",
      "Epoch1| Training Loss :0.011185970157384872\n",
      "Epoch1| Training Loss :0.0041258679702878\n",
      "Epoch1| Training Loss :0.18312384188175201\n",
      "Epoch1| Training Loss :0.00528221670538187\n",
      "Epoch1| Training Loss :0.026167768985033035\n",
      "Epoch1| Training Loss :0.012715117074549198\n",
      "Epoch1| Training Loss :0.01982215791940689\n",
      "Epoch1| Training Loss :0.044891342520713806\n",
      "Epoch1| Training Loss :0.02859489805996418\n",
      "Epoch1| Training Loss :0.1286429762840271\n",
      "Epoch1| Training Loss :0.031667642295360565\n",
      "Epoch1| Training Loss :0.03925327584147453\n",
      "Epoch1| Training Loss :0.06323927640914917\n",
      "Epoch1| Training Loss :0.009991895407438278\n",
      "Epoch1| Training Loss :0.004429445136338472\n",
      "Epoch1| Training Loss :0.027107760310173035\n",
      "Epoch1| Training Loss :0.02674691192805767\n",
      "Epoch1| Training Loss :0.00615733303129673\n",
      "Epoch1| Training Loss :0.03633113205432892\n",
      "Epoch1| Training Loss :0.03259654715657234\n",
      "Epoch1| Training Loss :0.011333616450428963\n",
      "Epoch1| Training Loss :0.018227403983473778\n",
      "Epoch1| Training Loss :0.030168110504746437\n",
      "Epoch1| Training Loss :0.015958372503519058\n",
      "Epoch1| Training Loss :0.01888807862997055\n",
      "Epoch1| Training Loss :0.02792074903845787\n",
      "Epoch1| Training Loss :0.0485110841691494\n",
      "Epoch1| Training Loss :0.11499341577291489\n",
      "Epoch1| Training Loss :0.020894289016723633\n",
      "Epoch1| Training Loss :0.0038490095175802708\n",
      "Epoch1| Training Loss :0.03917890414595604\n",
      "Epoch1| Training Loss :0.021582437679171562\n",
      "Epoch1| Training Loss :0.006474736146628857\n",
      "Epoch1| Training Loss :0.028168879449367523\n",
      "Epoch1| Training Loss :0.05686834454536438\n",
      "Epoch1| Training Loss :0.004004800692200661\n",
      "Epoch1| Training Loss :0.03596728667616844\n",
      "Epoch1| Training Loss :0.013135578483343124\n",
      "Epoch1| Training Loss :0.021790094673633575\n",
      "Epoch1| Training Loss :0.016484497115015984\n",
      "Epoch1| Training Loss :0.018646106123924255\n",
      "Epoch1| Training Loss :0.009924608282744884\n",
      "Epoch1| Training Loss :0.006129986606538296\n",
      "Epoch1| Training Loss :0.047400522977113724\n",
      "Epoch1| Training Loss :0.02465716563165188\n",
      "Epoch1| Training Loss :0.01180850900709629\n",
      "Epoch1| Training Loss :0.021970514208078384\n",
      "Epoch1| Training Loss :0.021937420591711998\n",
      "Epoch1| Training Loss :0.07838179171085358\n",
      "Epoch1| Training Loss :0.026227839291095734\n",
      "Epoch1| Training Loss :0.004629716742783785\n",
      "Epoch1| Training Loss :0.0022410587407648563\n",
      "Epoch1| Training Loss :0.004859355743974447\n",
      "Epoch1| Training Loss :0.014422851614654064\n",
      "Epoch1| Training Loss :0.03471248224377632\n",
      "Epoch1| Training Loss :0.05199039727449417\n",
      "Epoch1| Training Loss :0.007007604464888573\n",
      "Epoch1| Training Loss :0.0011216280981898308\n",
      "Epoch1| Training Loss :0.08092319965362549\n",
      "Epoch1| Training Loss :0.05674893781542778\n",
      "Epoch1| Training Loss :0.07441842555999756\n",
      "Epoch1| Training Loss :0.05609370023012161\n",
      "Epoch1| Training Loss :0.020027372986078262\n",
      "Epoch1| Training Loss :0.0017630967777222395\n",
      "Epoch1| Training Loss :0.010275758802890778\n",
      "Epoch1| Training Loss :0.059319451451301575\n",
      "Epoch1| Training Loss :0.005343304481357336\n",
      "Epoch1| Training Loss :0.03638723865151405\n",
      "Epoch1| Training Loss :0.00457673380151391\n",
      "Epoch1| Training Loss :0.09958094358444214\n",
      "Epoch1| Training Loss :0.03644825145602226\n",
      "Epoch1| Training Loss :0.03956519812345505\n",
      "Epoch1| Training Loss :0.0024129380472004414\n",
      "Epoch1| Training Loss :0.04551557078957558\n",
      "Epoch1| Training Loss :0.01092202216386795\n",
      "Epoch1| Training Loss :0.0077176885679364204\n",
      "Epoch1| Training Loss :0.01259157806634903\n",
      "Epoch1| Training Loss :0.008288683369755745\n",
      "Epoch1| Training Loss :0.005857902579009533\n",
      "Epoch1| Training Loss :0.05796677619218826\n",
      "Epoch1| Training Loss :0.0014604113530367613\n",
      "Epoch1| Training Loss :0.003971008583903313\n",
      "Epoch1| Training Loss :0.030238252133131027\n",
      "Epoch1| Training Loss :0.015190079808235168\n",
      "Epoch1| Training Loss :0.048049695789813995\n",
      "Epoch1| Training Loss :0.11730924248695374\n",
      "Epoch1| Training Loss :0.04075181111693382\n",
      "Epoch1| Training Loss :0.03001072257757187\n",
      "Epoch1| Training Loss :0.01797911524772644\n",
      "Epoch1| Training Loss :0.009560328908264637\n",
      "Epoch1| Training Loss :0.021297432482242584\n",
      "Epoch1| Training Loss :0.1832265555858612\n",
      "Epoch1| Training Loss :0.03279609978199005\n",
      "Epoch1| Training Loss :0.02902797982096672\n",
      "Epoch1| Training Loss :0.017209000885486603\n",
      "Epoch1| Training Loss :0.03570175915956497\n",
      "Epoch1| Training Loss :0.018926944583654404\n",
      "Epoch1| Training Loss :0.009917745366692543\n",
      "Epoch1| Training Loss :0.0032655056565999985\n",
      "Epoch1| Training Loss :0.015443776734173298\n",
      "Epoch1| Training Loss :0.007882228121161461\n",
      "Epoch1| Training Loss :0.1315595805644989\n",
      "Epoch1| Training Loss :0.012113126926124096\n",
      "Epoch1| Training Loss :0.018022308126091957\n",
      "Epoch1| Training Loss :0.04754902422428131\n",
      "Epoch1| Training Loss :0.00257760938256979\n",
      "Epoch1| Training Loss :0.03733428567647934\n",
      "Epoch1| Training Loss :0.05902634561061859\n",
      "Epoch1| Training Loss :0.008057838305830956\n",
      "Epoch1| Training Loss :0.0007347582140937448\n",
      "Epoch1| Training Loss :0.016194194555282593\n",
      "Epoch1| Training Loss :0.012029499746859074\n",
      "Epoch1| Training Loss :0.010350538417696953\n",
      "Epoch1| Training Loss :0.12521342933177948\n",
      "Epoch1| Training Loss :0.030552370473742485\n",
      "Epoch1| Training Loss :0.005109041929244995\n",
      "Epoch1| Training Loss :0.03488686680793762\n",
      "Epoch1| Training Loss :0.036910369992256165\n",
      "Epoch1| Training Loss :0.0053153024055063725\n",
      "Epoch1| Training Loss :0.0048280744813382626\n",
      "Epoch1| Training Loss :0.01958751492202282\n",
      "Epoch1| Training Loss :0.02621632069349289\n",
      "Epoch1| Training Loss :0.019387932494282722\n",
      "Epoch1| Training Loss :0.03908280283212662\n",
      "Epoch1| Training Loss :0.019920220598578453\n",
      "Epoch1| Training Loss :0.007623659446835518\n",
      "Epoch1| Training Loss :0.015471851453185081\n",
      "Epoch1| Training Loss :0.1545129120349884\n",
      "Epoch1| Training Loss :0.003633304964751005\n",
      "Epoch1| Training Loss :0.008270010352134705\n",
      "Epoch1| Training Loss :0.0030061868019402027\n",
      "Epoch1| Training Loss :0.028938448056578636\n",
      "Epoch1| Training Loss :0.033432990312576294\n",
      "Epoch1| Training Loss :0.009240299463272095\n",
      "Epoch1| Training Loss :0.06935828179121017\n",
      "Epoch1| Training Loss :0.016400782391428947\n",
      "Epoch1| Training Loss :0.12684454023838043\n",
      "Epoch1| Training Loss :0.006945568602532148\n",
      "Epoch1| Training Loss :0.05614064633846283\n",
      "Epoch1| Training Loss :0.012192944064736366\n",
      "Epoch1| Training Loss :0.048346441239118576\n",
      "Epoch1| Training Loss :0.009095709770917892\n",
      "Epoch1| Training Loss :0.04765385761857033\n",
      "Epoch1| Training Loss :0.06472557783126831\n",
      "Epoch1| Training Loss :0.011962833814322948\n",
      "Epoch1| Training Loss :0.005605567246675491\n",
      "Epoch1| Training Loss :0.02138388343155384\n",
      "Epoch1| Training Loss :0.010408344678580761\n",
      "Epoch1| Training Loss :0.04218495637178421\n",
      "Epoch1| Training Loss :0.015351596288383007\n",
      "Epoch1| Training Loss :0.014479263685643673\n",
      "Epoch1| Training Loss :0.0029910884331911802\n",
      "Epoch1| Training Loss :0.05262026563286781\n",
      "Epoch1| Training Loss :0.028493596240878105\n",
      "Epoch1| Training Loss :0.001806397456675768\n",
      "Epoch1| Training Loss :0.09019152820110321\n",
      "Epoch1| Training Loss :0.0915873646736145\n",
      "Epoch1| Training Loss :0.013349724002182484\n",
      "Epoch1| Training Loss :0.0641075074672699\n",
      "Epoch1| Training Loss :0.017864396795630455\n",
      "Epoch1| Training Loss :0.002538491040468216\n",
      "Epoch1| Training Loss :0.015463132411241531\n",
      "Epoch1| Training Loss :0.02732940763235092\n",
      "Epoch1| Training Loss :0.014689523726701736\n",
      "Epoch1| Training Loss :0.02302122488617897\n",
      "Epoch1| Training Loss :0.045043088495731354\n",
      "Epoch1| Training Loss :0.008374443277716637\n",
      "Epoch1| Training Loss :0.020789191126823425\n",
      "Epoch1| Training Loss :0.15293185412883759\n",
      "Epoch1| Training Loss :0.00477134995162487\n",
      "Epoch1| Training Loss :0.002309825737029314\n",
      "Epoch1| Training Loss :0.022357499226927757\n",
      "Epoch1| Training Loss :0.0021792249754071236\n",
      "Epoch1| Training Loss :0.013368591666221619\n",
      "Epoch1| Training Loss :0.04930417239665985\n",
      "Epoch1| Training Loss :0.0016985749825835228\n",
      "Epoch1| Training Loss :0.011923898011446\n",
      "Epoch1| Training Loss :0.023658260703086853\n",
      "Epoch1| Training Loss :0.03369094058871269\n",
      "Epoch1| Training Loss :0.019660938531160355\n",
      "Epoch1| Training Loss :0.010002536699175835\n",
      "Epoch1| Training Loss :0.04286310076713562\n",
      "Epoch1| Training Loss :0.029546864330768585\n",
      "Epoch1| Training Loss :0.013961544260382652\n",
      "Epoch1| Training Loss :0.03367919474840164\n",
      "Epoch1| Training Loss :0.005483467597514391\n",
      "Epoch1| Training Loss :0.12163414806127548\n",
      "Epoch1| Training Loss :0.07698647677898407\n",
      "Epoch1| Training Loss :0.01028927881270647\n",
      "Epoch1| Training Loss :0.0059248716570436954\n",
      "Epoch1| Training Loss :0.0036431332118809223\n",
      "Epoch1| Training Loss :0.023627378046512604\n",
      "Epoch1| Training Loss :0.008072919212281704\n",
      "Epoch1| Training Loss :0.07190048694610596\n",
      "Epoch1| Training Loss :0.1002316027879715\n",
      "Epoch1| Training Loss :0.011126173660159111\n",
      "Epoch1| Training Loss :0.027628988027572632\n",
      "Epoch1| Training Loss :0.008450289256870747\n",
      "Epoch1| Training Loss :0.08221514523029327\n",
      "Epoch1| Training Loss :0.002638308797031641\n",
      "Epoch1| Training Loss :0.1158793494105339\n",
      "Epoch1| Training Loss :0.01757076196372509\n",
      "Epoch1| Training Loss :0.005937075708061457\n",
      "Epoch1| Training Loss :0.05469610542058945\n",
      "Epoch1| Training Loss :0.018064098432660103\n",
      "Epoch1| Training Loss :0.012588083744049072\n",
      "Epoch1| Training Loss :0.002064974047243595\n",
      "Epoch1| Training Loss :0.0710722878575325\n",
      "Epoch1| Training Loss :0.0064719058573246\n",
      "Epoch1| Training Loss :0.013416150584816933\n",
      "Epoch1| Training Loss :0.011368096806108952\n",
      "Epoch1| Training Loss :0.003271590918302536\n",
      "Epoch1| Training Loss :0.08098432421684265\n",
      "Epoch1| Training Loss :0.0011027012951672077\n",
      "Epoch1| Training Loss :0.0034442683681845665\n",
      "Epoch1| Training Loss :0.002149533946067095\n",
      "Epoch1| Training Loss :0.04839271679520607\n",
      "Epoch1| Training Loss :0.013689374551177025\n",
      "Epoch1| Training Loss :0.021076608449220657\n",
      "Epoch1| Training Loss :0.00510913273319602\n",
      "Epoch1| Training Loss :0.007068895269185305\n",
      "Epoch1| Training Loss :0.01711985468864441\n",
      "Epoch1| Training Loss :0.019451918080449104\n",
      "Epoch1| Training Loss :0.058870311826467514\n",
      "Epoch1| Training Loss :0.02498411014676094\n",
      "Epoch1| Training Loss :0.022812822833657265\n",
      "Epoch1| Training Loss :0.00611141137778759\n",
      "Epoch1| Training Loss :0.004982256330549717\n",
      "Epoch1| Training Loss :0.017128990963101387\n",
      "Epoch1| Training Loss :0.01726250723004341\n",
      "Epoch1| Training Loss :0.008888263255357742\n",
      "Epoch1| Training Loss :0.03809139505028725\n",
      "Epoch1| Training Loss :0.1409822255373001\n",
      "Epoch1| Training Loss :0.1162818968296051\n",
      "Epoch1| Training Loss :0.03988621011376381\n",
      "Epoch1| Training Loss :0.016561269760131836\n",
      "Epoch1| Training Loss :0.015803707763552666\n",
      "Epoch1| Training Loss :0.013078076764941216\n",
      "Epoch1| Training Loss :0.08168657124042511\n",
      "Epoch1| Training Loss :0.0016196684446185827\n",
      "Epoch1| Training Loss :0.027360975742340088\n",
      "Epoch1| Training Loss :0.02417263202369213\n",
      "Epoch1| Training Loss :0.04860523343086243\n",
      "Epoch1| Training Loss :0.02890435978770256\n",
      "Epoch1| Training Loss :0.06151746213436127\n",
      "Epoch1| Training Loss :0.02225472405552864\n",
      "Epoch1| Training Loss :0.028729887679219246\n",
      "Epoch1| Training Loss :0.034039150923490524\n",
      "Epoch1| Training Loss :0.024634022265672684\n",
      "Epoch1| Training Loss :0.00575144262984395\n",
      "Epoch1| Training Loss :0.12541700899600983\n",
      "Epoch1| Training Loss :0.004093195777386427\n",
      "Epoch1| Training Loss :0.0069673145189881325\n",
      "Epoch1| Training Loss :0.009526330977678299\n",
      "Epoch1| Training Loss :0.04672251641750336\n",
      "Epoch1| Training Loss :0.02474161982536316\n",
      "Epoch1| Training Loss :0.017337976023554802\n",
      "Epoch1| Training Loss :0.025003990158438683\n",
      "Epoch1| Training Loss :0.10628778487443924\n",
      "Epoch1| Training Loss :0.059085968881845474\n",
      "Epoch1| Training Loss :0.0025583431124687195\n",
      "Epoch1| Training Loss :0.004319373518228531\n",
      "Epoch1| Training Loss :0.0004944048123434186\n",
      "Epoch1| Training Loss :0.0035101831890642643\n",
      "Epoch1| Training Loss :0.07660417258739471\n",
      "Epoch1| Training Loss :0.007766674738377333\n",
      "Epoch1| Training Loss :0.027616627514362335\n",
      "Epoch1| Training Loss :0.04956667870283127\n",
      "Epoch1| Training Loss :0.026141317561268806\n",
      "Epoch1| Training Loss :0.026189271360635757\n",
      "Epoch1| Training Loss :0.04878827929496765\n",
      "Epoch1| Training Loss :0.00191298418212682\n",
      "Epoch1| Training Loss :0.007243460509926081\n",
      "Epoch1| Training Loss :0.01965351775288582\n",
      "Epoch1| Training Loss :0.005296748131513596\n",
      "Epoch1| Training Loss :0.023590944707393646\n",
      "Epoch1| Training Loss :0.02805900014936924\n",
      "Epoch1| Training Loss :0.0024842768907546997\n",
      "Epoch1| Training Loss :0.028337594121694565\n",
      "Epoch1| Training Loss :0.05638224631547928\n",
      "Epoch1| Training Loss :0.02897609770298004\n",
      "Epoch1| Training Loss :0.01111806370317936\n",
      "Epoch1| Training Loss :0.0019112583249807358\n",
      "Epoch1| Training Loss :0.06612272560596466\n",
      "Epoch1| Training Loss :0.049709782004356384\n",
      "Epoch1| Training Loss :0.01551654003560543\n",
      "Epoch1| Training Loss :0.03501678258180618\n",
      "Epoch1| Training Loss :0.012304525822401047\n",
      "Epoch1| Training Loss :0.13618499040603638\n",
      "Epoch1| Training Loss :0.009150234051048756\n",
      "Epoch1| Training Loss :0.003982116002589464\n",
      "Epoch1| Training Loss :0.004795687273144722\n",
      "Epoch1| Training Loss :0.029134435579180717\n",
      "Epoch1| Training Loss :0.006799085531383753\n",
      "Epoch1| Training Loss :0.03209102898836136\n",
      "Epoch1| Training Loss :0.010092511773109436\n",
      "Epoch1| Training Loss :0.02049785479903221\n",
      "Epoch1| Training Loss :0.14735326170921326\n",
      "Epoch1| Training Loss :0.019782377406954765\n",
      "Epoch1| Training Loss :0.0050088828429579735\n",
      "Epoch1| Training Loss :0.01249542273581028\n",
      "Epoch1| Training Loss :0.022729719057679176\n",
      "Epoch1| Training Loss :0.021464746445417404\n",
      "Epoch1| Training Loss :0.0880865827202797\n",
      "Epoch1| Training Loss :0.01935506798326969\n",
      "Epoch1| Training Loss :0.01562090776860714\n",
      "Epoch1| Training Loss :0.0732707679271698\n",
      "Epoch1| Training Loss :0.036237750202417374\n",
      "Epoch1| Training Loss :0.0814482718706131\n",
      "Epoch1| Training Loss :0.007140068802982569\n",
      "Epoch1| Training Loss :0.0030303599778562784\n",
      "Epoch1| Training Loss :0.004411486908793449\n",
      "Epoch1| Training Loss :0.008578585460782051\n",
      "Epoch1| Training Loss :0.01151534728705883\n",
      "Epoch1| Training Loss :0.008211790584027767\n",
      "Epoch1| Training Loss :0.0045572370290756226\n",
      "Epoch1| Training Loss :0.021098701283335686\n",
      "Epoch1| Training Loss :0.024242660030722618\n",
      "Epoch1| Training Loss :0.016848186030983925\n",
      "Epoch1| Training Loss :0.006150559987872839\n",
      "Epoch1| Training Loss :0.029100237414240837\n",
      "Epoch1| Training Loss :0.009790499694645405\n",
      "Epoch1| Training Loss :0.1502368152141571\n",
      "Epoch1| Training Loss :0.004343198146671057\n",
      "Epoch1| Training Loss :0.005137910600751638\n",
      "Epoch1| Training Loss :0.004083926323801279\n",
      "Epoch1| Training Loss :0.04084407165646553\n",
      "Epoch1| Training Loss :0.028816215693950653\n",
      "Epoch1| Training Loss :0.06519122421741486\n",
      "Epoch1| Training Loss :0.09051991254091263\n",
      "Epoch1| Training Loss :0.02882799506187439\n",
      "Epoch1| Training Loss :0.007965347729623318\n",
      "Epoch1| Training Loss :0.1252831071615219\n",
      "Epoch1| Training Loss :0.05783997103571892\n",
      "Epoch1| Training Loss :0.01655857264995575\n",
      "Epoch1| Training Loss :0.03287271782755852\n",
      "Epoch1| Training Loss :0.13231003284454346\n",
      "Epoch1| Training Loss :0.04367813467979431\n",
      "Epoch1| Training Loss :0.0813225582242012\n",
      "Epoch1| Training Loss :0.012031367048621178\n",
      "Epoch1| Training Loss :0.01933145523071289\n",
      "Epoch1| Training Loss :0.04166353866457939\n",
      "Epoch1| Training Loss :0.014006170444190502\n",
      "Epoch1| Training Loss :0.03882961720228195\n",
      "Epoch1| Training Loss :0.0061759669333696365\n",
      "Epoch1| Training Loss :0.003028170671314001\n",
      "Epoch1| Training Loss :0.009382576681673527\n",
      "Epoch1| Training Loss :0.0020557132083922625\n",
      "Epoch1| Training Loss :0.07162155956029892\n",
      "Epoch1| Training Loss :0.027931392192840576\n",
      "Epoch1| Training Loss :0.0032881111837923527\n",
      "Epoch1| Training Loss :0.026502925902605057\n",
      "Epoch1| Training Loss :0.05686458200216293\n",
      "Epoch1| Training Loss :0.012819397263228893\n",
      "Epoch1| Training Loss :0.03026229701936245\n",
      "Epoch1| Training Loss :0.025706734508275986\n",
      "Epoch1| Training Loss :0.04554950073361397\n",
      "Epoch1| Training Loss :0.06253085285425186\n",
      "Epoch1| Training Loss :0.0572483204305172\n",
      "Epoch1| Training Loss :0.157282292842865\n",
      "Epoch1| Training Loss :0.012688694521784782\n",
      "Epoch1| Training Loss :0.07376986742019653\n",
      "Epoch1| Training Loss :0.021552221849560738\n",
      "Epoch1| Training Loss :0.1646200567483902\n",
      "Epoch1| Training Loss :0.04335436969995499\n",
      "Epoch1| Training Loss :0.07866568863391876\n",
      "Epoch1| Training Loss :0.023448344320058823\n",
      "Epoch1| Training Loss :0.015503760427236557\n",
      "Epoch1| Training Loss :0.025063032284379005\n",
      "Epoch1| Training Loss :0.043606385588645935\n",
      "Epoch1| Training Loss :0.10114932060241699\n",
      "Epoch1| Training Loss :0.005936835426837206\n",
      "Epoch1| Training Loss :0.029443949460983276\n",
      "Epoch1| Training Loss :0.07521452754735947\n",
      "Epoch1| Training Loss :0.011777758598327637\n",
      "Epoch1| Training Loss :0.03887255862355232\n",
      "Epoch1| Training Loss :0.10394217073917389\n",
      "Epoch1| Training Loss :0.07978321611881256\n",
      "Epoch1| Training Loss :0.018808351829648018\n",
      "Epoch1| Training Loss :0.008260657079517841\n",
      "Epoch1| Training Loss :0.03582942485809326\n",
      "Epoch1| Training Loss :0.016524184495210648\n",
      "Epoch1| Training Loss :0.14562082290649414\n",
      "Epoch1| Training Loss :0.0065704165026545525\n",
      "Epoch1| Training Loss :0.05440346524119377\n",
      "Epoch1| Training Loss :0.07591822743415833\n",
      "Epoch1| Training Loss :0.04260794445872307\n",
      "Epoch1| Training Loss :0.015398817136883736\n",
      "Epoch1| Training Loss :0.0107923224568367\n",
      "Epoch1| Training Loss :0.07133963704109192\n",
      "Epoch1| Training Loss :0.03178795799612999\n",
      "Epoch1| Training Loss :0.015157000161707401\n",
      "Epoch1| Training Loss :0.06532547622919083\n",
      "Epoch1| Training Loss :0.02257528156042099\n",
      "Epoch1| Training Loss :0.0063868132419884205\n",
      "Epoch1| Training Loss :0.0068567413836717606\n",
      "Epoch1| Training Loss :0.017166540026664734\n",
      "Epoch1| Training Loss :0.035663262009620667\n",
      "Epoch1| Training Loss :0.06795351207256317\n",
      "Epoch1| Training Loss :0.004609484225511551\n",
      "Epoch1| Training Loss :0.03909064084291458\n",
      "Epoch1| Training Loss :0.008887138217687607\n",
      "Epoch1| Training Loss :0.10872559249401093\n",
      "Epoch1| Training Loss :0.01679406315088272\n",
      "Epoch1| Training Loss :0.01690102182328701\n",
      "Epoch1| Training Loss :0.0013268105685710907\n",
      "Epoch1| Training Loss :0.05069116875529289\n",
      "Epoch1| Training Loss :0.01181040145456791\n",
      "Epoch1| Training Loss :0.025321565568447113\n",
      "Epoch1| Training Loss :0.021936632692813873\n",
      "Epoch1| Training Loss :0.002708477433770895\n",
      "Epoch1| Training Loss :0.01296289637684822\n",
      "Epoch1| Training Loss :0.007702084258198738\n",
      "Epoch1| Training Loss :0.006939389742910862\n",
      "Epoch1| Training Loss :0.028685273602604866\n",
      "Epoch1| Training Loss :0.001349786063656211\n",
      "Epoch1| Training Loss :0.07148885726928711\n",
      "Epoch1| Training Loss :0.0014795586466789246\n",
      "Epoch1| Training Loss :0.038837164640426636\n",
      "Epoch1| Training Loss :0.0033106673508882523\n",
      "Epoch1| Training Loss :0.0066211652010679245\n",
      "Epoch1| Training Loss :0.025194495916366577\n",
      "Epoch1| Training Loss :0.0008544770535081625\n",
      "Epoch1| Training Loss :0.008968772366642952\n",
      "Epoch1| Training Loss :0.021165881305933\n",
      "Epoch1| Training Loss :0.011447497643530369\n",
      "Epoch1| Training Loss :0.1312418282032013\n",
      "Epoch1| Training Loss :0.017258036881685257\n",
      "Epoch1| Training Loss :0.029066499322652817\n",
      "Epoch1| Training Loss :0.0036028698086738586\n",
      "Epoch1| Training Loss :0.06748036295175552\n",
      "Epoch1| Training Loss :0.021626979112625122\n",
      "Epoch1| Training Loss :0.034666307270526886\n",
      "Epoch1| Training Loss :0.0069139376282691956\n",
      "Epoch1| Training Loss :0.015859289094805717\n",
      "Epoch1| Training Loss :0.019153514876961708\n",
      "Epoch1| Training Loss :0.03659733384847641\n",
      "Epoch1| Training Loss :0.047959763556718826\n",
      "Epoch1| Training Loss :0.013596540316939354\n",
      "Epoch1| Training Loss :0.03751375526189804\n",
      "Epoch1| Training Loss :0.004417902324348688\n",
      "Epoch1| Training Loss :0.09257644414901733\n",
      "Epoch1| Training Loss :0.1279653012752533\n",
      "Epoch1| Training Loss :0.01812150329351425\n",
      "Epoch1| Training Loss :0.011806396767497063\n",
      "Epoch1| Training Loss :0.02552943304181099\n",
      "Epoch1| Training Loss :0.015785586088895798\n",
      "Epoch1| Training Loss :0.181032195687294\n",
      "Epoch1| Training Loss :0.008767101913690567\n",
      "Epoch1| Training Loss :0.011905688792467117\n",
      "Epoch1| Training Loss :0.009715531021356583\n",
      "Epoch1| Training Loss :0.013076269999146461\n",
      "Epoch1| Training Loss :0.047495268285274506\n",
      "Epoch1| Training Loss :0.1542905867099762\n",
      "Epoch1| Training Loss :0.0042586117051541805\n",
      "Epoch1| Training Loss :0.008162222802639008\n",
      "Epoch1| Training Loss :0.0029343971982598305\n",
      "Epoch1| Training Loss :0.12838003039360046\n",
      "Epoch1| Training Loss :0.03304878994822502\n",
      "Epoch1| Training Loss :0.0014544535661116242\n",
      "Epoch1| Training Loss :0.014995412901043892\n",
      "Epoch1| Training Loss :0.04991286247968674\n",
      "Epoch1| Training Loss :0.1111384928226471\n",
      "Epoch1| Training Loss :0.1112804189324379\n",
      "Epoch1| Training Loss :0.01935296691954136\n",
      "Epoch1| Training Loss :0.08217249065637589\n",
      "Epoch1| Training Loss :0.1119636744260788\n",
      "Epoch1| Training Loss :0.03772461786866188\n",
      "Epoch1| Training Loss :0.02096230909228325\n",
      "Epoch1| Training Loss :0.031966499984264374\n",
      "Epoch1| Training Loss :0.041879069060087204\n",
      "Epoch1| Training Loss :0.07151438295841217\n",
      "Epoch1| Training Loss :0.027417847886681557\n",
      "Epoch1| Training Loss :0.00684481393545866\n",
      "Epoch1| Training Loss :0.09218806773424149\n",
      "Epoch1| Training Loss :0.02275111898779869\n",
      "Epoch1| Training Loss :0.0192571971565485\n",
      "Epoch1| Training Loss :0.06891606748104095\n",
      "Epoch1| Training Loss :0.014796876348555088\n",
      "Epoch1| Training Loss :0.01207762211561203\n",
      "Epoch1| Training Loss :0.023971514776349068\n",
      "Epoch1| Training Loss :0.005802953615784645\n",
      "Epoch1| Training Loss :0.035901207476854324\n",
      "Epoch1| Training Loss :0.005052388645708561\n",
      "Epoch1| Training Loss :0.12661972641944885\n",
      "Epoch1| Training Loss :0.025553051382303238\n",
      "Epoch1| Training Loss :0.009320411831140518\n",
      "Epoch1| Training Loss :0.027131030336022377\n",
      "Epoch1| Training Loss :0.02193661965429783\n",
      "Epoch1| Training Loss :0.02602597512304783\n",
      "Epoch1| Training Loss :0.005396871827542782\n",
      "Epoch1| Training Loss :0.026191681623458862\n",
      "Epoch1| Training Loss :0.01736098900437355\n",
      "Epoch1| Training Loss :0.031339097768068314\n",
      "Epoch1| Training Loss :0.0037221431266516447\n",
      "Epoch1| Training Loss :0.03064097836613655\n",
      "Epoch1| Training Loss :0.005959976930171251\n",
      "Epoch1| Training Loss :0.006337523460388184\n",
      "Epoch1| Training Loss :0.06174428015947342\n",
      "Epoch1| Training Loss :0.05814044550061226\n",
      "Epoch1| Training Loss :0.00549367256462574\n",
      "Epoch1| Training Loss :0.05858614668250084\n",
      "Epoch1| Training Loss :0.06406913697719574\n",
      "Epoch1| Training Loss :0.03803562372922897\n",
      "Epoch1| Training Loss :0.06074189022183418\n",
      "Epoch1| Training Loss :0.010080574080348015\n",
      "Epoch1| Training Loss :0.001240873709321022\n",
      "Epoch1| Training Loss :0.026085197925567627\n",
      "Epoch1| Training Loss :0.002574130892753601\n",
      "Epoch1| Training Loss :0.00510589312762022\n",
      "Epoch1| Training Loss :0.07908463478088379\n",
      "Epoch1| Training Loss :0.012343372218310833\n",
      "Epoch1| Training Loss :0.030566390603780746\n",
      "Epoch1| Training Loss :0.01864634081721306\n",
      "Epoch1| Training Loss :0.011514937505126\n",
      "Epoch1| Training Loss :0.04196961596608162\n",
      "Epoch1| Training Loss :0.0031151678413152695\n",
      "Epoch1| Training Loss :0.010115519165992737\n",
      "Epoch1| Training Loss :0.0007068440900184214\n",
      "Epoch1| Training Loss :0.0435749851167202\n",
      "Epoch1| Training Loss :0.008065768517553806\n",
      "Epoch1| Training Loss :0.17200011014938354\n",
      "Epoch1| Training Loss :0.004258099477738142\n",
      "Epoch1| Training Loss :0.006215978413820267\n",
      "Epoch1| Training Loss :0.029059885069727898\n",
      "Epoch1| Training Loss :0.004149037878960371\n",
      "Epoch1| Training Loss :0.05572015047073364\n",
      "Epoch1| Training Loss :0.032704684883356094\n",
      "Epoch1| Training Loss :0.007782255299389362\n",
      "Epoch1| Training Loss :0.03988398239016533\n",
      "Epoch1| Training Loss :0.037988193333148956\n",
      "Epoch1| Training Loss :0.03694766014814377\n",
      "Epoch1| Training Loss :0.028338762000203133\n",
      "Epoch1| Training Loss :0.16724973917007446\n",
      "Epoch1| Training Loss :0.08157990872859955\n",
      "Epoch1| Training Loss :0.0296483151614666\n",
      "Epoch1| Training Loss :0.02167542092502117\n",
      "Epoch1| Training Loss :0.014800176955759525\n",
      "Epoch1| Training Loss :0.036576349288225174\n",
      "Epoch1| Training Loss :0.03072824701666832\n",
      "Epoch1| Training Loss :0.0693242996931076\n",
      "Epoch1| Training Loss :0.008695404976606369\n",
      "Epoch1| Training Loss :0.03474148362874985\n",
      "Epoch1| Training Loss :0.024973584339022636\n",
      "Epoch1| Training Loss :0.07534927129745483\n",
      "Epoch1| Training Loss :0.0014838948845863342\n",
      "Epoch1| Training Loss :0.014985430985689163\n",
      "Epoch1| Training Loss :0.002192770130932331\n",
      "Epoch1| Training Loss :0.11547744274139404\n",
      "Epoch1| Training Loss :0.0006961631588637829\n",
      "Test loss : 0.038483358919620514\n",
      "Test loss : 0.013654395006597042\n",
      "Test loss : 0.013757833279669285\n",
      "Test loss : 0.07850855588912964\n",
      "Test loss : 0.002287101000547409\n",
      "Test loss : 0.007127587217837572\n",
      "Test loss : 0.028069589287042618\n",
      "Test loss : 0.01703048124909401\n",
      "Test loss : 0.029471183195710182\n",
      "Test loss : 0.0016278800321742892\n",
      "Test loss : 0.02628718502819538\n",
      "Test loss : 0.013875335454940796\n",
      "Test loss : 0.10273577272891998\n",
      "Test loss : 0.027840252965688705\n",
      "Test loss : 0.026540666818618774\n",
      "Test loss : 0.04090234637260437\n",
      "Test loss : 0.009600717574357986\n",
      "Test loss : 0.012428287416696548\n",
      "Test loss : 0.004098092205822468\n",
      "Test loss : 0.012476922944188118\n",
      "Test loss : 0.006823440082371235\n",
      "Test loss : 0.006050290539860725\n",
      "Test loss : 0.03403528779745102\n",
      "Test loss : 0.009251115843653679\n",
      "Test loss : 0.04534327611327171\n",
      "Test loss : 0.005093537271022797\n",
      "Test loss : 0.03520764410495758\n",
      "Test loss : 0.01675495319068432\n",
      "Test loss : 0.009465636685490608\n",
      "Test loss : 0.005694460589438677\n",
      "Test loss : 0.005333995446562767\n",
      "Test loss : 0.02460663951933384\n",
      "Test loss : 0.09323396533727646\n",
      "Test loss : 0.004393150098621845\n",
      "Test loss : 0.0038662501610815525\n",
      "Test loss : 0.015378221869468689\n",
      "Test loss : 0.004657326266169548\n",
      "Test loss : 0.002226842800155282\n",
      "Test loss : 0.023678764700889587\n",
      "Test loss : 0.04112084209918976\n",
      "Test loss : 0.0026016058400273323\n",
      "Test loss : 0.05731502175331116\n",
      "Test loss : 0.11378535628318787\n",
      "Test loss : 0.008218368515372276\n",
      "Test loss : 0.04944674298167229\n",
      "Test loss : 0.0209821704775095\n",
      "Test loss : 0.004795192275196314\n",
      "Test loss : 0.00589544465765357\n",
      "Test loss : 0.018662258982658386\n",
      "Test loss : 0.021487344056367874\n",
      "Test loss : 0.08814464509487152\n",
      "Test loss : 0.0017214668914675713\n",
      "Test loss : 0.009543364867568016\n",
      "Test loss : 0.09803631156682968\n",
      "Test loss : 0.007584897801280022\n",
      "Test loss : 0.005901116877794266\n",
      "Test loss : 0.04143429175019264\n",
      "Test loss : 0.013042138889431953\n",
      "Test loss : 0.002837488194927573\n",
      "Test loss : 0.008503571152687073\n",
      "Test loss : 0.0425240583717823\n",
      "Test loss : 0.03443938493728638\n",
      "Test loss : 0.016922995448112488\n",
      "Test loss : 0.002334105782210827\n",
      "Test loss : 0.04028667137026787\n",
      "Test loss : 0.012519224546849728\n",
      "Test loss : 0.015015189535915852\n",
      "Test loss : 0.032962676137685776\n",
      "Test loss : 0.007036811672151089\n",
      "Test loss : 0.05353768169879913\n",
      "Test loss : 0.002527320757508278\n",
      "Test loss : 0.025580797344446182\n",
      "Test loss : 0.04007164016366005\n",
      "Test loss : 0.016502341255545616\n",
      "Test loss : 0.002245949115604162\n",
      "Test loss : 0.035408709198236465\n",
      "Test loss : 0.0424499437212944\n",
      "Test loss : 0.010100623592734337\n",
      "Test loss : 0.003291999688372016\n",
      "Test loss : 0.0061133201234042645\n",
      "Test loss : 0.03082222491502762\n",
      "Test loss : 0.024213584139943123\n",
      "Test loss : 0.07263903319835663\n",
      "Test loss : 0.0025895102880895138\n",
      "Test loss : 0.03294029086828232\n",
      "Test loss : 0.017714891582727432\n",
      "Test loss : 0.005398616194725037\n",
      "Test loss : 0.007212631404399872\n",
      "Test loss : 0.21946749091148376\n",
      "Test loss : 0.07823994755744934\n",
      "Test loss : 0.01341948751360178\n",
      "Test loss : 0.09744873642921448\n",
      "Test loss : 0.0355537049472332\n",
      "Test loss : 0.014121539890766144\n",
      "Test loss : 0.021862711757421494\n",
      "Test loss : 0.008584313094615936\n",
      "Test loss : 0.04180460423231125\n",
      "Test loss : 0.015973450616002083\n",
      "Test loss : 0.027917658910155296\n",
      "Test loss : 0.18594223260879517\n",
      "Test loss : 0.06209593266248703\n",
      "Test loss : 0.01063056755810976\n",
      "Test loss : 0.0603678859770298\n",
      "Test loss : 0.05182268097996712\n",
      "Test loss : 0.005960209760814905\n",
      "Test loss : 0.016347773373126984\n",
      "Test loss : 0.017504436895251274\n",
      "Test loss : 0.00266758119687438\n",
      "Test loss : 0.032305773347616196\n",
      "Test loss : 0.0028568808920681477\n",
      "Test loss : 0.08185156434774399\n",
      "Test loss : 0.006712626200169325\n",
      "Test loss : 0.0013453655410557985\n",
      "Test loss : 0.006611942313611507\n",
      "Test loss : 0.007485623471438885\n",
      "Test loss : 0.013888903893530369\n",
      "Test loss : 0.00822892040014267\n",
      "Test loss : 0.11828846484422684\n",
      "Test loss : 0.007687713019549847\n",
      "Test loss : 0.007592717185616493\n",
      "Test loss : 0.014119801111519337\n",
      "Test loss : 0.0034232637844979763\n",
      "Test loss : 0.03723359853029251\n",
      "Test loss : 0.01221050601452589\n",
      "Test loss : 0.041765838861465454\n",
      "Test loss : 0.00199721148237586\n",
      "Test loss : 0.004793782718479633\n",
      "Test loss : 0.010221458040177822\n",
      "Test loss : 0.10628928989171982\n",
      "Test loss : 0.006368980277329683\n",
      "Test loss : 0.001945393392816186\n",
      "Test loss : 0.01959671825170517\n",
      "Test loss : 0.004140017554163933\n",
      "Test loss : 0.04630723223090172\n",
      "Test loss : 0.026985248550772667\n",
      "Test loss : 0.00767137436196208\n",
      "Test loss : 0.01379952859133482\n",
      "Test loss : 0.017120633274316788\n",
      "Test loss : 0.014620048925280571\n",
      "Test loss : 0.009607445448637009\n",
      "Test loss : 0.0021375776268541813\n",
      "Test loss : 0.0071869525127112865\n",
      "Test loss : 0.0008194601396098733\n",
      "Test loss : 0.014420630410313606\n",
      "Test loss : 0.06920775026082993\n",
      "Test loss : 0.014281438663601875\n",
      "Test loss : 0.014370404183864594\n",
      "Test loss : 0.050570543855428696\n",
      "Test loss : 0.002734087873250246\n",
      "Test loss : 0.017440518364310265\n",
      "Test loss : 0.013766408897936344\n",
      "Test loss : 0.0017420516815036535\n",
      "Test loss : 0.0021327477879822254\n",
      "Test loss : 0.0535915270447731\n",
      "Test loss : 0.01075661089271307\n",
      "Test loss : 0.007382464595139027\n",
      "Test loss : 0.06576725095510483\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1 , epochs):\n",
    "    train(model , train_dataloader , device , optimizer , epoch)\n",
    "    test(model , test_dataloader , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c6c2efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "img , label = next(iter(test_dataloader))\n",
    "img , label = img.to(device) , label.to(device)\n",
    "pred = model(img[0].unsqueeze(0))\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c70ea4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , pred = torch.max(pred , 1 ) # tensor pred is of form [batch , classes] so dim 1 is classes it finds the max value within classes \n",
    "# _ is actual max value and pred is the position where max value is located i.e the class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f2b7da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2], device='mps:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50bc611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
